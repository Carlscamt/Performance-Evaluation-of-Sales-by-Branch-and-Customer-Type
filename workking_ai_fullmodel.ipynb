{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Carlscamt/Performance-Evaluation-of-Sales-by-Branch-and-Customer-Type/blob/main/workking_ai_fullmodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cObAsfaTwZW-",
        "outputId": "97b9a175-7512-409f-cdca-e4972d3a638e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/65.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.4/65.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.8/235.8 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m94.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.7/99.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.8/292.8 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m85.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.0/278.0 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.0/93.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m499.2/499.2 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.8/129.8 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for undetected-chromedriver (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for litellm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mDownloading Chromium 138.0.7204.23 (playwright build v1179)\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/chromium/1179/chromium-linux.zip\u001b[22m\n",
            "\u001b[1G171.6 MiB [] 0% 0.0s\u001b[0K\u001b[1G171.6 MiB [] 0% 54.3s\u001b[0K\u001b[1G171.6 MiB [] 0% 24.2s\u001b[0K\u001b[1G171.6 MiB [] 0% 14.1s\u001b[0K\u001b[1G171.6 MiB [] 0% 7.4s\u001b[0K\u001b[1G171.6 MiB [] 1% 4.9s\u001b[0K\u001b[1G171.6 MiB [] 2% 3.8s\u001b[0K\u001b[1G171.6 MiB [] 3% 3.1s\u001b[0K\u001b[1G171.6 MiB [] 4% 2.9s\u001b[0K\u001b[1G171.6 MiB [] 5% 2.7s\u001b[0K\u001b[1G171.6 MiB [] 6% 2.7s\u001b[0K\u001b[1G171.6 MiB [] 7% 2.6s\u001b[0K\u001b[1G171.6 MiB [] 8% 2.6s\u001b[0K\u001b[1G171.6 MiB [] 9% 2.6s\u001b[0K\u001b[1G171.6 MiB [] 10% 2.5s\u001b[0K\u001b[1G171.6 MiB [] 11% 2.3s\u001b[0K\u001b[1G171.6 MiB [] 12% 2.2s\u001b[0K\u001b[1G171.6 MiB [] 13% 2.1s\u001b[0K\u001b[1G171.6 MiB [] 15% 2.0s\u001b[0K\u001b[1G171.6 MiB [] 16% 1.9s\u001b[0K\u001b[1G171.6 MiB [] 17% 1.8s\u001b[0K\u001b[1G171.6 MiB [] 18% 1.8s\u001b[0K\u001b[1G171.6 MiB [] 20% 1.7s\u001b[0K\u001b[1G171.6 MiB [] 21% 1.7s\u001b[0K\u001b[1G171.6 MiB [] 22% 1.6s\u001b[0K\u001b[1G171.6 MiB [] 23% 1.6s\u001b[0K\u001b[1G171.6 MiB [] 24% 1.5s\u001b[0K\u001b[1G171.6 MiB [] 25% 1.5s\u001b[0K\u001b[1G171.6 MiB [] 26% 1.5s\u001b[0K\u001b[1G171.6 MiB [] 26% 1.6s\u001b[0K\u001b[1G171.6 MiB [] 27% 1.5s\u001b[0K\u001b[1G171.6 MiB [] 29% 1.4s\u001b[0K\u001b[1G171.6 MiB [] 30% 1.4s\u001b[0K\u001b[1G171.6 MiB [] 31% 1.4s\u001b[0K\u001b[1G171.6 MiB [] 32% 1.3s\u001b[0K\u001b[1G171.6 MiB [] 34% 1.3s\u001b[0K\u001b[1G171.6 MiB [] 35% 1.2s\u001b[0K\u001b[1G171.6 MiB [] 36% 1.2s\u001b[0K\u001b[1G171.6 MiB [] 38% 1.1s\u001b[0K\u001b[1G171.6 MiB [] 39% 1.1s\u001b[0K\u001b[1G171.6 MiB [] 40% 1.1s\u001b[0K\u001b[1G171.6 MiB [] 41% 1.0s\u001b[0K\u001b[1G171.6 MiB [] 42% 1.0s\u001b[0K\u001b[1G171.6 MiB [] 43% 1.0s\u001b[0K\u001b[1G171.6 MiB [] 44% 1.0s\u001b[0K\u001b[1G171.6 MiB [] 46% 1.0s\u001b[0K\u001b[1G171.6 MiB [] 47% 1.0s\u001b[0K\u001b[1G171.6 MiB [] 49% 0.9s\u001b[0K\u001b[1G171.6 MiB [] 50% 0.9s\u001b[0K\u001b[1G171.6 MiB [] 52% 0.9s\u001b[0K\u001b[1G171.6 MiB [] 53% 0.8s\u001b[0K\u001b[1G171.6 MiB [] 55% 0.8s\u001b[0K\u001b[1G171.6 MiB [] 56% 0.8s\u001b[0K\u001b[1G171.6 MiB [] 57% 0.8s\u001b[0K\u001b[1G171.6 MiB [] 59% 0.7s\u001b[0K\u001b[1G171.6 MiB [] 60% 0.7s\u001b[0K\u001b[1G171.6 MiB [] 61% 0.7s\u001b[0K\u001b[1G171.6 MiB [] 62% 0.6s\u001b[0K\u001b[1G171.6 MiB [] 63% 0.6s\u001b[0K\u001b[1G171.6 MiB [] 64% 0.6s\u001b[0K\u001b[1G171.6 MiB [] 65% 0.6s\u001b[0K\u001b[1G171.6 MiB [] 66% 0.6s\u001b[0K\u001b[1G171.6 MiB [] 67% 0.6s\u001b[0K\u001b[1G171.6 MiB [] 68% 0.6s\u001b[0K\u001b[1G171.6 MiB [] 68% 0.5s\u001b[0K\u001b[1G171.6 MiB [] 69% 0.5s\u001b[0K\u001b[1G171.6 MiB [] 70% 0.5s\u001b[0K\u001b[1G171.6 MiB [] 71% 0.5s\u001b[0K\u001b[1G171.6 MiB [] 72% 0.5s\u001b[0K\u001b[1G171.6 MiB [] 73% 0.5s\u001b[0K\u001b[1G171.6 MiB [] 74% 0.5s\u001b[0K\u001b[1G171.6 MiB [] 76% 0.4s\u001b[0K\u001b[1G171.6 MiB [] 77% 0.4s\u001b[0K\u001b[1G171.6 MiB [] 78% 0.4s\u001b[0K\u001b[1G171.6 MiB [] 79% 0.4s\u001b[0K\u001b[1G171.6 MiB [] 80% 0.3s\u001b[0K\u001b[1G171.6 MiB [] 82% 0.3s\u001b[0K\u001b[1G171.6 MiB [] 83% 0.3s\u001b[0K\u001b[1G171.6 MiB [] 84% 0.3s\u001b[0K\u001b[1G171.6 MiB [] 85% 0.2s\u001b[0K\u001b[1G171.6 MiB [] 87% 0.2s\u001b[0K\u001b[1G171.6 MiB [] 88% 0.2s\u001b[0K\u001b[1G171.6 MiB [] 89% 0.2s\u001b[0K\u001b[1G171.6 MiB [] 90% 0.2s\u001b[0K\u001b[1G171.6 MiB [] 92% 0.1s\u001b[0K\u001b[1G171.6 MiB [] 93% 0.1s\u001b[0K\u001b[1G171.6 MiB [] 94% 0.1s\u001b[0K\u001b[1G171.6 MiB [] 95% 0.1s\u001b[0K\u001b[1G171.6 MiB [] 96% 0.1s\u001b[0K\u001b[1G171.6 MiB [] 97% 0.0s\u001b[0K\u001b[1G171.6 MiB [] 99% 0.0s\u001b[0K\u001b[1G171.6 MiB [] 100% 0.0s\u001b[0K\n",
            "Chromium 138.0.7204.23 (playwright build v1179) downloaded to /root/.cache/ms-playwright/chromium-1179\n",
            "Downloading Chromium Headless Shell 138.0.7204.23 (playwright build v1179)\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/chromium/1179/chromium-headless-shell-linux.zip\u001b[22m\n",
            "\u001b[1G104.5 MiB [] 0% 0.0s\u001b[0K\u001b[1G104.5 MiB [] 0% 27.6s\u001b[0K\u001b[1G104.5 MiB [] 0% 27.0s\u001b[0K\u001b[1G104.5 MiB [] 0% 12.3s\u001b[0K\u001b[1G104.5 MiB [] 0% 8.3s\u001b[0K\u001b[1G104.5 MiB [] 1% 6.6s\u001b[0K\u001b[1G104.5 MiB [] 1% 5.5s\u001b[0K\u001b[1G104.5 MiB [] 2% 5.3s\u001b[0K\u001b[1G104.5 MiB [] 3% 5.4s\u001b[0K\u001b[1G104.5 MiB [] 3% 5.2s\u001b[0K\u001b[1G104.5 MiB [] 4% 4.2s\u001b[0K\u001b[1G104.5 MiB [] 5% 3.5s\u001b[0K\u001b[1G104.5 MiB [] 7% 3.0s\u001b[0K\u001b[1G104.5 MiB [] 8% 2.9s\u001b[0K\u001b[1G104.5 MiB [] 8% 3.1s\u001b[0K\u001b[1G104.5 MiB [] 9% 3.0s\u001b[0K\u001b[1G104.5 MiB [] 10% 2.9s\u001b[0K\u001b[1G104.5 MiB [] 12% 2.6s\u001b[0K\u001b[1G104.5 MiB [] 13% 2.4s\u001b[0K\u001b[1G104.5 MiB [] 14% 2.4s\u001b[0K\u001b[1G104.5 MiB [] 15% 2.4s\u001b[0K\u001b[1G104.5 MiB [] 16% 2.3s\u001b[0K\u001b[1G104.5 MiB [] 17% 2.2s\u001b[0K\u001b[1G104.5 MiB [] 18% 2.2s\u001b[0K\u001b[1G104.5 MiB [] 19% 2.2s\u001b[0K\u001b[1G104.5 MiB [] 20% 2.1s\u001b[0K\u001b[1G104.5 MiB [] 21% 2.1s\u001b[0K\u001b[1G104.5 MiB [] 22% 2.0s\u001b[0K\u001b[1G104.5 MiB [] 24% 1.9s\u001b[0K\u001b[1G104.5 MiB [] 25% 1.9s\u001b[0K\u001b[1G104.5 MiB [] 26% 1.8s\u001b[0K\u001b[1G104.5 MiB [] 27% 1.8s\u001b[0K\u001b[1G104.5 MiB [] 28% 1.8s\u001b[0K\u001b[1G104.5 MiB [] 28% 1.7s\u001b[0K\u001b[1G104.5 MiB [] 29% 1.7s\u001b[0K\u001b[1G104.5 MiB [] 30% 1.7s\u001b[0K\u001b[1G104.5 MiB [] 31% 1.7s\u001b[0K\u001b[1G104.5 MiB [] 32% 1.7s\u001b[0K\u001b[1G104.5 MiB [] 33% 1.7s\u001b[0K\u001b[1G104.5 MiB [] 34% 1.6s\u001b[0K\u001b[1G104.5 MiB [] 36% 1.6s\u001b[0K\u001b[1G104.5 MiB [] 37% 1.5s\u001b[0K\u001b[1G104.5 MiB [] 38% 1.5s\u001b[0K\u001b[1G104.5 MiB [] 40% 1.4s\u001b[0K\u001b[1G104.5 MiB [] 41% 1.4s\u001b[0K\u001b[1G104.5 MiB [] 42% 1.4s\u001b[0K\u001b[1G104.5 MiB [] 43% 1.4s\u001b[0K\u001b[1G104.5 MiB [] 44% 1.3s\u001b[0K\u001b[1G104.5 MiB [] 45% 1.3s\u001b[0K\u001b[1G104.5 MiB [] 46% 1.3s\u001b[0K\u001b[1G104.5 MiB [] 48% 1.2s\u001b[0K\u001b[1G104.5 MiB [] 50% 1.1s\u001b[0K\u001b[1G104.5 MiB [] 52% 1.1s\u001b[0K\u001b[1G104.5 MiB [] 53% 1.0s\u001b[0K\u001b[1G104.5 MiB [] 55% 1.0s\u001b[0K\u001b[1G104.5 MiB [] 56% 0.9s\u001b[0K\u001b[1G104.5 MiB [] 57% 0.9s\u001b[0K\u001b[1G104.5 MiB [] 58% 0.9s\u001b[0K\u001b[1G104.5 MiB [] 59% 0.8s\u001b[0K\u001b[1G104.5 MiB [] 60% 0.8s\u001b[0K\u001b[1G104.5 MiB [] 61% 0.8s\u001b[0K\u001b[1G104.5 MiB [] 62% 0.8s\u001b[0K\u001b[1G104.5 MiB [] 63% 0.8s\u001b[0K\u001b[1G104.5 MiB [] 64% 0.7s\u001b[0K\u001b[1G104.5 MiB [] 65% 0.7s\u001b[0K\u001b[1G104.5 MiB [] 67% 0.7s\u001b[0K\u001b[1G104.5 MiB [] 68% 0.6s\u001b[0K\u001b[1G104.5 MiB [] 69% 0.6s\u001b[0K\u001b[1G104.5 MiB [] 70% 0.6s\u001b[0K\u001b[1G104.5 MiB [] 71% 0.6s\u001b[0K\u001b[1G104.5 MiB [] 72% 0.6s\u001b[0K\u001b[1G104.5 MiB [] 73% 0.5s\u001b[0K\u001b[1G104.5 MiB [] 74% 0.5s\u001b[0K\u001b[1G104.5 MiB [] 75% 0.5s\u001b[0K\u001b[1G104.5 MiB [] 76% 0.5s\u001b[0K\u001b[1G104.5 MiB [] 77% 0.4s\u001b[0K\u001b[1G104.5 MiB [] 78% 0.4s\u001b[0K\u001b[1G104.5 MiB [] 79% 0.4s\u001b[0K\u001b[1G104.5 MiB [] 80% 0.4s\u001b[0K\u001b[1G104.5 MiB [] 81% 0.4s\u001b[0K\u001b[1G104.5 MiB [] 82% 0.3s\u001b[0K\u001b[1G104.5 MiB [] 84% 0.3s\u001b[0K\u001b[1G104.5 MiB [] 85% 0.3s\u001b[0K\u001b[1G104.5 MiB [] 86% 0.3s\u001b[0K\u001b[1G104.5 MiB [] 87% 0.2s\u001b[0K\u001b[1G104.5 MiB [] 88% 0.2s\u001b[0K\u001b[1G104.5 MiB [] 90% 0.2s\u001b[0K\u001b[1G104.5 MiB [] 91% 0.2s\u001b[0K\u001b[1G104.5 MiB [] 92% 0.1s\u001b[0K\u001b[1G104.5 MiB [] 93% 0.1s\u001b[0K\u001b[1G104.5 MiB [] 94% 0.1s\u001b[0K\u001b[1G104.5 MiB [] 95% 0.1s\u001b[0K\u001b[1G104.5 MiB [] 96% 0.1s\u001b[0K\u001b[1G104.5 MiB [] 97% 0.1s\u001b[0K\u001b[1G104.5 MiB [] 97% 0.0s\u001b[0K\u001b[1G104.5 MiB [] 98% 0.0s\u001b[0K\u001b[1G104.5 MiB [] 100% 0.0s\u001b[0K\n",
            "Chromium Headless Shell 138.0.7204.23 (playwright build v1179) downloaded to /root/.cache/ms-playwright/chromium_headless_shell-1179\n",
            "Downloading Firefox 139.0 (playwright build v1488)\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/firefox/1488/firefox-ubuntu-22.04.zip\u001b[22m\n",
            "\u001b[1G92.3 MiB [] 0% 0.0s\u001b[0K\u001b[1G92.3 MiB [] 0% 31.0s\u001b[0K\u001b[1G92.3 MiB [] 0% 13.7s\u001b[0K\u001b[1G92.3 MiB [] 0% 9.1s\u001b[0K\u001b[1G92.3 MiB [] 1% 4.6s\u001b[0K\u001b[1G92.3 MiB [] 2% 4.0s\u001b[0K\u001b[1G92.3 MiB [] 3% 2.9s\u001b[0K\u001b[1G92.3 MiB [] 4% 2.3s\u001b[0K\u001b[1G92.3 MiB [] 6% 1.9s\u001b[0K\u001b[1G92.3 MiB [] 7% 1.8s\u001b[0K\u001b[1G92.3 MiB [] 9% 1.6s\u001b[0K\u001b[1G92.3 MiB [] 10% 1.6s\u001b[0K\u001b[1G92.3 MiB [] 11% 1.6s\u001b[0K\u001b[1G92.3 MiB [] 12% 1.6s\u001b[0K\u001b[1G92.3 MiB [] 13% 1.5s\u001b[0K\u001b[1G92.3 MiB [] 15% 1.4s\u001b[0K\u001b[1G92.3 MiB [] 16% 1.4s\u001b[0K\u001b[1G92.3 MiB [] 17% 1.4s\u001b[0K\u001b[1G92.3 MiB [] 18% 1.3s\u001b[0K\u001b[1G92.3 MiB [] 19% 1.3s\u001b[0K\u001b[1G92.3 MiB [] 21% 1.2s\u001b[0K\u001b[1G92.3 MiB [] 23% 1.1s\u001b[0K\u001b[1G92.3 MiB [] 24% 1.2s\u001b[0K\u001b[1G92.3 MiB [] 26% 1.1s\u001b[0K\u001b[1G92.3 MiB [] 27% 1.0s\u001b[0K\u001b[1G92.3 MiB [] 29% 1.0s\u001b[0K\u001b[1G92.3 MiB [] 32% 0.9s\u001b[0K\u001b[1G92.3 MiB [] 34% 0.9s\u001b[0K\u001b[1G92.3 MiB [] 36% 0.8s\u001b[0K\u001b[1G92.3 MiB [] 38% 0.8s\u001b[0K\u001b[1G92.3 MiB [] 39% 0.8s\u001b[0K\u001b[1G92.3 MiB [] 40% 0.8s\u001b[0K\u001b[1G92.3 MiB [] 42% 0.7s\u001b[0K\u001b[1G92.3 MiB [] 44% 0.7s\u001b[0K\u001b[1G92.3 MiB [] 46% 0.6s\u001b[0K\u001b[1G92.3 MiB [] 48% 0.6s\u001b[0K\u001b[1G92.3 MiB [] 49% 0.6s\u001b[0K\u001b[1G92.3 MiB [] 50% 0.6s\u001b[0K\u001b[1G92.3 MiB [] 53% 0.6s\u001b[0K\u001b[1G92.3 MiB [] 55% 0.5s\u001b[0K\u001b[1G92.3 MiB [] 57% 0.5s\u001b[0K\u001b[1G92.3 MiB [] 59% 0.5s\u001b[0K\u001b[1G92.3 MiB [] 60% 0.5s\u001b[0K\u001b[1G92.3 MiB [] 61% 0.4s\u001b[0K\u001b[1G92.3 MiB [] 64% 0.4s\u001b[0K\u001b[1G92.3 MiB [] 66% 0.4s\u001b[0K\u001b[1G92.3 MiB [] 68% 0.4s\u001b[0K\u001b[1G92.3 MiB [] 70% 0.3s\u001b[0K\u001b[1G92.3 MiB [] 72% 0.3s\u001b[0K\u001b[1G92.3 MiB [] 74% 0.3s\u001b[0K\u001b[1G92.3 MiB [] 76% 0.2s\u001b[0K\u001b[1G92.3 MiB [] 79% 0.2s\u001b[0K\u001b[1G92.3 MiB [] 80% 0.2s\u001b[0K\u001b[1G92.3 MiB [] 83% 0.2s\u001b[0K\u001b[1G92.3 MiB [] 85% 0.2s\u001b[0K\u001b[1G92.3 MiB [] 87% 0.1s\u001b[0K\u001b[1G92.3 MiB [] 89% 0.1s\u001b[0K\u001b[1G92.3 MiB [] 91% 0.1s\u001b[0K\u001b[1G92.3 MiB [] 93% 0.1s\u001b[0K\u001b[1G92.3 MiB [] 95% 0.0s\u001b[0K\u001b[1G92.3 MiB [] 98% 0.0s\u001b[0K\u001b[1G92.3 MiB [] 100% 0.0s\u001b[0K\n",
            "Firefox 139.0 (playwright build v1488) downloaded to /root/.cache/ms-playwright/firefox-1488\n",
            "Downloading Webkit 18.5 (playwright build v2182)\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/webkit/2182/webkit-ubuntu-22.04.zip\u001b[22m\n",
            "\u001b[1G93.7 MiB [] 0% 0.0s\u001b[0K\u001b[1G93.7 MiB [] 0% 28.5s\u001b[0K\u001b[1G93.7 MiB [] 0% 14.1s\u001b[0K\u001b[1G93.7 MiB [] 0% 7.6s\u001b[0K\u001b[1G93.7 MiB [] 1% 4.4s\u001b[0K\u001b[1G93.7 MiB [] 2% 3.2s\u001b[0K\u001b[1G93.7 MiB [] 3% 2.7s\u001b[0K\u001b[1G93.7 MiB [] 4% 2.3s\u001b[0K\u001b[1G93.7 MiB [] 6% 2.1s\u001b[0K\u001b[1G93.7 MiB [] 7% 1.9s\u001b[0K\u001b[1G93.7 MiB [] 8% 1.8s\u001b[0K\u001b[1G93.7 MiB [] 9% 1.7s\u001b[0K\u001b[1G93.7 MiB [] 10% 1.8s\u001b[0K\u001b[1G93.7 MiB [] 12% 1.8s\u001b[0K\u001b[1G93.7 MiB [] 13% 1.8s\u001b[0K\u001b[1G93.7 MiB [] 14% 1.8s\u001b[0K\u001b[1G93.7 MiB [] 15% 1.7s\u001b[0K\u001b[1G93.7 MiB [] 16% 1.7s\u001b[0K\u001b[1G93.7 MiB [] 17% 1.7s\u001b[0K\u001b[1G93.7 MiB [] 18% 1.7s\u001b[0K\u001b[1G93.7 MiB [] 19% 1.7s\u001b[0K\u001b[1G93.7 MiB [] 20% 1.6s\u001b[0K\u001b[1G93.7 MiB [] 22% 1.5s\u001b[0K\u001b[1G93.7 MiB [] 23% 1.4s\u001b[0K\u001b[1G93.7 MiB [] 24% 1.5s\u001b[0K\u001b[1G93.7 MiB [] 25% 1.4s\u001b[0K\u001b[1G93.7 MiB [] 26% 1.4s\u001b[0K\u001b[1G93.7 MiB [] 27% 1.3s\u001b[0K\u001b[1G93.7 MiB [] 29% 1.3s\u001b[0K\u001b[1G93.7 MiB [] 31% 1.2s\u001b[0K\u001b[1G93.7 MiB [] 32% 1.2s\u001b[0K\u001b[1G93.7 MiB [] 33% 1.1s\u001b[0K\u001b[1G93.7 MiB [] 35% 1.1s\u001b[0K\u001b[1G93.7 MiB [] 36% 1.0s\u001b[0K\u001b[1G93.7 MiB [] 38% 1.0s\u001b[0K\u001b[1G93.7 MiB [] 39% 1.0s\u001b[0K\u001b[1G93.7 MiB [] 40% 0.9s\u001b[0K\u001b[1G93.7 MiB [] 42% 0.9s\u001b[0K\u001b[1G93.7 MiB [] 43% 0.9s\u001b[0K\u001b[1G93.7 MiB [] 44% 0.9s\u001b[0K\u001b[1G93.7 MiB [] 46% 0.8s\u001b[0K\u001b[1G93.7 MiB [] 48% 0.8s\u001b[0K\u001b[1G93.7 MiB [] 49% 0.8s\u001b[0K\u001b[1G93.7 MiB [] 51% 0.8s\u001b[0K\u001b[1G93.7 MiB [] 52% 0.8s\u001b[0K\u001b[1G93.7 MiB [] 54% 0.7s\u001b[0K\u001b[1G93.7 MiB [] 55% 0.7s\u001b[0K\u001b[1G93.7 MiB [] 57% 0.7s\u001b[0K\u001b[1G93.7 MiB [] 59% 0.6s\u001b[0K\u001b[1G93.7 MiB [] 60% 0.6s\u001b[0K\u001b[1G93.7 MiB [] 62% 0.6s\u001b[0K\u001b[1G93.7 MiB [] 64% 0.5s\u001b[0K\u001b[1G93.7 MiB [] 65% 0.5s\u001b[0K\u001b[1G93.7 MiB [] 67% 0.5s\u001b[0K\u001b[1G93.7 MiB [] 68% 0.4s\u001b[0K\u001b[1G93.7 MiB [] 69% 0.4s\u001b[0K\u001b[1G93.7 MiB [] 71% 0.4s\u001b[0K\u001b[1G93.7 MiB [] 73% 0.4s\u001b[0K\u001b[1G93.7 MiB [] 74% 0.4s\u001b[0K\u001b[1G93.7 MiB [] 76% 0.3s\u001b[0K\u001b[1G93.7 MiB [] 77% 0.3s\u001b[0K\u001b[1G93.7 MiB [] 78% 0.3s\u001b[0K\u001b[1G93.7 MiB [] 80% 0.3s\u001b[0K\u001b[1G93.7 MiB [] 82% 0.2s\u001b[0K\u001b[1G93.7 MiB [] 83% 0.2s\u001b[0K\u001b[1G93.7 MiB [] 85% 0.2s\u001b[0K\u001b[1G93.7 MiB [] 86% 0.2s\u001b[0K\u001b[1G93.7 MiB [] 88% 0.2s\u001b[0K\u001b[1G93.7 MiB [] 89% 0.1s\u001b[0K\u001b[1G93.7 MiB [] 91% 0.1s\u001b[0K\u001b[1G93.7 MiB [] 92% 0.1s\u001b[0K\u001b[1G93.7 MiB [] 94% 0.1s\u001b[0K\u001b[1G93.7 MiB [] 96% 0.0s\u001b[0K\u001b[1G93.7 MiB [] 99% 0.0s\u001b[0K\u001b[1G93.7 MiB [] 100% 0.0s\u001b[0K\n",
            "Webkit 18.5 (playwright build v2182) downloaded to /root/.cache/ms-playwright/webkit-2182\n",
            "Downloading FFMPEG playwright build v1011\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/ffmpeg/1011/ffmpeg-linux.zip\u001b[22m\n",
            "\u001b[1G2.3 MiB [] 0% 0.0s\u001b[0K\u001b[1G2.3 MiB [] 2% 0.7s\u001b[0K\u001b[1G2.3 MiB [] 11% 0.3s\u001b[0K\u001b[1G2.3 MiB [] 26% 0.1s\u001b[0K\u001b[1G2.3 MiB [] 66% 0.0s\u001b[0K\u001b[1G2.3 MiB [] 100% 0.0s\u001b[0K\n",
            "FFMPEG playwright build v1011 downloaded to /root/.cache/ms-playwright/ffmpeg-1011\n",
            "Playwright Host validation warning: \n",
            "╔══════════════════════════════════════════════════════╗\n",
            "║ Host system is missing dependencies to run browsers. ║\n",
            "║ Missing libraries:                                   ║\n",
            "║     libwoff2dec.so.1.0.2                             ║\n",
            "║     libgstgl-1.0.so.0                                ║\n",
            "║     libgstcodecparsers-1.0.so.0                      ║\n",
            "║     libavif.so.13                                    ║\n",
            "║     libharfbuzz-icu.so.0                             ║\n",
            "║     libenchant-2.so.2                                ║\n",
            "║     libsecret-1.so.0                                 ║\n",
            "║     libhyphen.so.0                                   ║\n",
            "║     libmanette-0.2.so.0                              ║\n",
            "╚══════════════════════════════════════════════════════╝\n",
            "    at validateDependenciesLinux (/usr/local/lib/python3.11/dist-packages/playwright/driver/package/lib/server/registry/dependencies.js:269:9)\n",
            "\u001b[90m    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\u001b[39m\n",
            "    at async Registry._validateHostRequirements (/usr/local/lib/python3.11/dist-packages/playwright/driver/package/lib/server/registry/index.js:927:14)\n",
            "    at async Registry._validateHostRequirementsForExecutableIfNeeded (/usr/local/lib/python3.11/dist-packages/playwright/driver/package/lib/server/registry/index.js:1049:7)\n",
            "    at async Registry.validateHostRequirementsForExecutablesIfNeeded (/usr/local/lib/python3.11/dist-packages/playwright/driver/package/lib/server/registry/index.js:1038:7)\n",
            "    at async t.<anonymous> (/usr/local/lib/python3.11/dist-packages/playwright/driver/package/lib/cli/program.js:217:7)\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install pandas numpy xgboost scikit-learn glicko2 tqdm requests playwright beautifulsoup4 unidecode selenium cloudscraper undetected-chromedriver crawl4ai --quiet\n",
        "!playwright install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBdKAcaZwFDI",
        "outputId": "99804b77-443a-4fe5-da78-f37d05b7f270"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🎾 TENNIS ATP MATCH-WINNER MODEL v6.0 (Complete GPU Version)\n",
            "🚀 Clean baseline with GPU training support\n",
            "============================================================\n",
            "📥 Downloading ATP match data...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading match CSVs: 100%|██████████| 171/171 [00:49<00:00,  3.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔧 Processing matches and building features...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Parsing matches: 100%|██████████| 138/138 [08:46<00:00,  3.82s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Created feature frame with 415,091 matches\n",
            "💾 Saving feature frame for backtesting...\n",
            "✅ Feature frame saved successfully\n",
            "🧮 Building feature matrix...\n",
            "✅ Feature matrix: 415,091 samples, 34 features\n",
            "🤖 Training model...\n",
            "⚠️  nvidia-smi not found, using CPU\n",
            "🖥️ Training with CPU\n",
            "📊 Training on 331,982 samples...\n",
            "\n",
            "🎯 CPU TRAINING RESULTS:\n",
            "   Accuracy: 68.108%\n",
            "   AUC: 0.751\n",
            "   Training samples: 331,982\n",
            "   Validation samples: 83,109\n",
            "\n",
            "🏆 TOP 20 MOST IMPORTANT FEATURES:\n",
            "                feature  importance\n",
            "        glicko_win_prob    0.314484\n",
            "            glicko_diff    0.263709\n",
            " glicko_confidence_diff    0.115917\n",
            "          rank_pts_diff    0.034850\n",
            "              rank_diff    0.031640\n",
            "                rd_diff    0.023684\n",
            "          surf_elo_diff    0.019847\n",
            "     ranking_volatility    0.014938\n",
            "    rd_uncertainty_flag    0.013855\n",
            "        form_confidence    0.012329\n",
            "      freshness_penalty    0.012167\n",
            "               age_diff    0.010255\n",
            "          is_grand_slam    0.009328\n",
            "                h2h_adv    0.008870\n",
            "                 max_rd    0.008442\n",
            "          activity_diff    0.008281\n",
            "     confidence_product    0.008069\n",
            "surface_experience_diff    0.007821\n",
            "            height_diff    0.007726\n",
            "confidence_weighted_elo    0.007344\n",
            "💾 Saving model...\n",
            "\n",
            "🎾 COMPLETE GPU MODEL FINISHED!\n",
            "📊 Features: 34\n",
            "💾 Model saved: tennis_model_gpu_complete_20250709_180515.json\n",
            "💾 Encoder saved: surface_encoder_complete_20250709_180515.pkl\n",
            "💾 Feature importance saved: feature_importance_complete_20250709_180515.csv\n",
            "============================================================\n",
            "🏆 Ready for production use!\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Tennis ATP Match-Winner Model – v6.0 (Complete GPU Version)\n",
        "• Jeff Sackmann match data (2010-2024)\n",
        "• Enhanced with Glicko uncertainty, activity tracking, and confidence weighting\n",
        "• Strictly pre-match information → no data-leakage\n",
        "• GPU-accelerated training with CPU fallback\n",
        "• Expected accuracy ≈ 72-74% AUC ≈ 0.80-0.82\n",
        "\"\"\"\n",
        "\n",
        "# ╔══ 0. Imports & Configuration ════════════════════════════════════════════╗\n",
        "import os, sys, warnings, pickle, requests\n",
        "import pandas as pd, numpy as np\n",
        "from tqdm import tqdm\n",
        "import glicko2, xgboost as xgb\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "import math\n",
        "from datetime import datetime, timedelta\n",
        "from collections import defaultdict\n",
        "import subprocess\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "REPO = \"https://raw.githubusercontent.com/JeffSackmann/tennis_atp/master/\"\n",
        "DATA = \"tennis_atp_data\"\n",
        "MIN_YR = 2010\n",
        "\n",
        "# ╔══ 1. Helper Functions ════════════════════════════════════════════════════╗\n",
        "def parse_date(x):\n",
        "    \"\"\"Safe date parsing function\"\"\"\n",
        "    if pd.isna(x): return pd.NaT\n",
        "    s = str(int(x)) if isinstance(x,(int,float)) else str(x)\n",
        "    for f in (\"%Y%m%d\",\"%Y-%m-%d\",\"%d/%m/%Y\",\"%m/%d/%Y\"):\n",
        "        try: return pd.to_datetime(s,format=f)\n",
        "        except: pass\n",
        "    return pd.to_datetime(s,errors=\"coerce\")\n",
        "\n",
        "def glicko_win_prob(r1, rd1, r2, rd2):\n",
        "    \"\"\"Calculate Glicko-2 win probability incorporating rating deviation uncertainty\"\"\"\n",
        "    q = math.log(10) / 400\n",
        "    g = 1 / math.sqrt(1 + 3 * q**2 * rd2**2 / (math.pi**2))\n",
        "    expected = 1 / (1 + 10**(-g * (r1 - r2) / 400))\n",
        "    return expected\n",
        "\n",
        "def calculate_confidence_weight(rd):\n",
        "    \"\"\"Convert rating deviation to confidence weight (0-1 scale)\"\"\"\n",
        "    return 1 / (1 + rd / 100)\n",
        "\n",
        "def check_gpu_availability():\n",
        "    \"\"\"Check if GPU is available for XGBoost training\"\"\"\n",
        "    try:\n",
        "        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
        "        if result.returncode == 0:\n",
        "            print(\"✅ GPU detected and available for training\")\n",
        "            return True\n",
        "        else:\n",
        "            print(\"⚠️  GPU not detected, using CPU\")\n",
        "            return False\n",
        "    except FileNotFoundError:\n",
        "        print(\"⚠️  nvidia-smi not found, using CPU\")\n",
        "        return False\n",
        "\n",
        "# ╔══ 2. Download Jeff Sackmann match CSVs ═══════════════════════════════════╗\n",
        "def download_csvs():\n",
        "    \"\"\"Download ATP match CSV files from Jeff Sackmann's repository\"\"\"\n",
        "    os.makedirs(DATA, exist_ok=True)\n",
        "    existing = [f for f in os.listdir(DATA)\n",
        "                if f.endswith(\".csv\") and \"matches\" in f and \"doubles\" not in f]\n",
        "    if existing:\n",
        "        print(f\"✅ Found {len(existing)} existing CSV files\")\n",
        "        return existing\n",
        "\n",
        "    todo  = [f\"atp_matches_{y}.csv\"         for y in range(1968,2025)]\n",
        "    todo += [f\"atp_matches_futures_{y}.csv\" for y in range(1968,2025)]\n",
        "    todo += [f\"atp_matches_qual_chall_{y}.csv\" for y in range(1968,2025)]\n",
        "\n",
        "    print(\"📥 Downloading ATP match data...\")\n",
        "    for fn in tqdm(todo, desc=\"Downloading match CSVs\"):\n",
        "        url = REPO + fn\n",
        "        try:\n",
        "            r = requests.get(url, timeout=30)\n",
        "            if r.ok:\n",
        "                open(os.path.join(DATA, fn), \"wb\").write(r.content)\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to download {fn}: {e}\")\n",
        "\n",
        "    return [f for f in os.listdir(DATA)\n",
        "            if f.endswith(\".csv\") and \"matches\" in f and \"doubles\" not in f]\n",
        "\n",
        "# ╔══ 3. Process matches → pre-match feature frame ═══════════════════════════╗\n",
        "def build_feature_frame(files):\n",
        "    \"\"\"Build feature frame with comprehensive tennis statistics and activity tracking\"\"\"\n",
        "    # Initialize tracking systems\n",
        "    glicko, elo = {}, {}\n",
        "    s_elo = {\"Hard\": {}, \"Clay\": {}, \"Grass\": {}}\n",
        "    h2h = {}\n",
        "    serve_hist = {}\n",
        "    activity_hist = {}\n",
        "    player_form = defaultdict(lambda: defaultdict(list))\n",
        "\n",
        "    rec = []\n",
        "\n",
        "    print(\"🔧 Processing matches and building features...\")\n",
        "    for fn in tqdm(files, desc=\"Parsing matches\"):\n",
        "        try:\n",
        "            df = pd.read_csv(os.path.join(DATA, fn), low_memory=False, on_bad_lines=\"skip\")\n",
        "            df[\"tourney_date\"] = df[\"tourney_date\"].apply(parse_date)\n",
        "            df = df.dropna(subset=[\"tourney_date\",\"winner_id\",\"loser_id\"])\n",
        "            df = df[df.tourney_date.dt.year >= MIN_YR]\n",
        "\n",
        "            # Safe conversion to integers\n",
        "            df[\"winner_id\"] = pd.to_numeric(df[\"winner_id\"], errors='coerce')\n",
        "            df[\"loser_id\"] = pd.to_numeric(df[\"loser_id\"], errors='coerce')\n",
        "            df = df.dropna(subset=[\"winner_id\",\"loser_id\"])\n",
        "            df = df.astype({\"winner_id\":int,\"loser_id\":int})\n",
        "            df = df.sort_values([\"tourney_date\",\"match_num\"] if \"match_num\" in df.columns else [\"tourney_date\"])\n",
        "\n",
        "            for _, r in df.iterrows():\n",
        "                w, l = r.winner_id, r.loser_id\n",
        "                current_date = r.tourney_date\n",
        "\n",
        "                # Initialize tracking for new players\n",
        "                for p in (w, l):\n",
        "                    glicko.setdefault(p, glicko2.Player())\n",
        "                    elo.setdefault(p, 1500)\n",
        "                    for s in s_elo:\n",
        "                        s_elo[s].setdefault(p, 1500)\n",
        "                    serve_hist.setdefault(p, dict(ace=8, df=3, fs=65, fw=75, n=0))\n",
        "                    activity_hist.setdefault(p, {\n",
        "                        \"last_match\": None,\n",
        "                        \"match_dates\": [],\n",
        "                        \"recent_results\": [],\n",
        "                        \"surface_matches\": {\"Hard\": 0, \"Clay\": 0, \"Grass\": 0}\n",
        "                    })\n",
        "\n",
        "                # Calculate activity metrics BEFORE the match\n",
        "                w_activity = activity_hist[w]\n",
        "                l_activity = activity_hist[l]\n",
        "\n",
        "                w_days_since = (current_date - w_activity[\"last_match\"]).days if w_activity[\"last_match\"] else 180\n",
        "                l_days_since = (current_date - l_activity[\"last_match\"]).days if l_activity[\"last_match\"] else 180\n",
        "\n",
        "                w_matches_90d = len([d for d in w_activity[\"match_dates\"] if (current_date - d).days <= 90])\n",
        "                l_matches_90d = len([d for d in l_activity[\"match_dates\"] if (current_date - d).days <= 90])\n",
        "\n",
        "                surface = r.get(\"surface\", \"Hard\") or \"Hard\"\n",
        "                if surface not in s_elo:\n",
        "                    surface = \"Hard\"\n",
        "\n",
        "                w_surface_matches = len([d for d in w_activity[\"match_dates\"] if (current_date - d).days <= 365])\n",
        "                l_surface_matches = len([d for d in l_activity[\"match_dates\"] if (current_date - d).days <= 365])\n",
        "\n",
        "                w_recent_form = np.mean(w_activity[\"recent_results\"][-10:]) if w_activity[\"recent_results\"] else 0.5\n",
        "                l_recent_form = np.mean(l_activity[\"recent_results\"][-10:]) if l_activity[\"recent_results\"] else 0.5\n",
        "\n",
        "                w_surface_form = np.mean(player_form[w][surface][-15:]) if player_form[w][surface] else 0.5\n",
        "                l_surface_form = np.mean(player_form[l][surface][-15:]) if player_form[l][surface] else 0.5\n",
        "\n",
        "                # Get ratings BEFORE the match\n",
        "                wp, lp = glicko[w], glicko[l]\n",
        "                w_se, l_se = s_elo[surface][w], s_elo[surface][l]\n",
        "\n",
        "                pair = tuple(sorted([w, l]))\n",
        "                h2h.setdefault(pair, [0, 0])\n",
        "                pre_h2h = h2h[pair][0] - h2h[pair][1] if pair[0] == w else h2h[pair][1] - h2h[pair][0]\n",
        "\n",
        "                W, L = serve_hist[w], serve_hist[l]\n",
        "\n",
        "                # Store match record with PRE-MATCH information only\n",
        "                rec.append(dict(\n",
        "                    date=current_date, surface=surface,\n",
        "                    tlevel=r.get(\"tourney_level\",\"A\"), draw=r.get(\"draw_size\",32),\n",
        "                    winner_id=w, loser_id=l,\n",
        "                    w_g=wp.rating, l_g=lp.rating,\n",
        "                    w_rd=wp.rd, l_rd=lp.rd,\n",
        "                    w_e=elo[w], l_e=elo[l],\n",
        "                    w_se=w_se, l_se=l_se,\n",
        "                    h2h=pre_h2h,\n",
        "                    w_rank=r.get(\"winner_rank\",100), l_rank=r.get(\"loser_rank\",100),\n",
        "                    w_pts=r.get(\"winner_rank_points\",1000), l_pts=r.get(\"loser_rank_points\",1000),\n",
        "                    w_age=r.get(\"winner_age\",25), l_age=r.get(\"loser_age\",25),\n",
        "                    w_ht=r.get(\"winner_ht\",180), l_ht=r.get(\"loser_ht\",180),\n",
        "                    w_hand=r.get(\"winner_hand\",\"R\"), l_hand=r.get(\"loser_hand\",\"R\"),\n",
        "                    w_ace=W[\"ace\"], l_ace=L[\"ace\"],\n",
        "                    w_df=W[\"df\"], l_df=L[\"df\"],\n",
        "                    w_fs=W[\"fs\"], l_fs=L[\"fs\"],\n",
        "                    w_fw=W[\"fw\"], l_fw=L[\"fw\"],\n",
        "                    w_form=w_surface_form, l_form=l_surface_form,\n",
        "                    w_days_since=w_days_since,\n",
        "                    l_days_since=l_days_since,\n",
        "                    w_matches_90d=w_matches_90d,\n",
        "                    l_matches_90d=l_matches_90d,\n",
        "                    w_surface_matches=w_surface_matches,\n",
        "                    l_surface_matches=l_surface_matches,\n",
        "                    w_recent_form=w_recent_form,\n",
        "                    l_recent_form=l_recent_form,\n",
        "                ))\n",
        "\n",
        "                # Update ratings and activity AFTER recording pre-match state\n",
        "                wp.update_player([lp.rating], [lp.rd], [1])\n",
        "                lp.update_player([wp.rating], [lp.rd], [0])\n",
        "\n",
        "                k = 32\n",
        "                expected = 1/(1+10**((elo[l]-elo[w])/400))\n",
        "                elo[w] += k*(1-expected); elo[l] -= k*(1-expected)\n",
        "\n",
        "                e_surface = s_elo[surface]\n",
        "                expected_s = 1/(1+10**((e_surface[l]-e_surface[w])/400))\n",
        "                e_surface[w] += k*(1-expected_s); e_surface[l] -= k*(1-expected_s)\n",
        "\n",
        "                h2h[pair][0 if pair[0]==w else 1] += 1\n",
        "\n",
        "                # Update activity tracking\n",
        "                for p, result in [(w, 1), (l, 0)]:\n",
        "                    activity_hist[p][\"last_match\"] = current_date\n",
        "                    activity_hist[p][\"match_dates\"].append(current_date)\n",
        "                    activity_hist[p][\"recent_results\"].append(result)\n",
        "                    activity_hist[p][\"surface_matches\"][surface] += 1\n",
        "                    player_form[p][surface].append(result)\n",
        "\n",
        "                    # Keep only last 50 matches for memory efficiency\n",
        "                    if len(activity_hist[p][\"match_dates\"]) > 50:\n",
        "                        activity_hist[p][\"match_dates\"] = activity_hist[p][\"match_dates\"][-50:]\n",
        "                        activity_hist[p][\"recent_results\"] = activity_hist[p][\"recent_results\"][-50:]\n",
        "\n",
        "                    if len(player_form[p][surface]) > 50:\n",
        "                        player_form[p][surface] = player_form[p][surface][-50:]\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {fn}: {e}\")\n",
        "            continue\n",
        "\n",
        "    return pd.DataFrame(rec)\n",
        "\n",
        "# ╔══ 4. Build feature matrix & target variable ══════════════════════════════╗\n",
        "def build_X_y(df):\n",
        "    \"\"\"Build feature matrix with comprehensive tennis features\"\"\"\n",
        "    le = LabelEncoder()\n",
        "    surf_enc = le.fit_transform(df.surface.fillna(\"Hard\"))\n",
        "\n",
        "    # Create random assignment for player perspective (fixes target variable issue)\n",
        "    np.random.seed(42)\n",
        "    p1 = np.random.rand(len(df)) > 0.5\n",
        "    y = p1.astype(int)  # Target: 1 if assigned \"player 1\" was the actual winner\n",
        "\n",
        "    # Calculate confidence weights\n",
        "    df[\"w_confidence\"] = df.w_rd.apply(calculate_confidence_weight)\n",
        "    df[\"l_confidence\"] = df.l_rd.apply(calculate_confidence_weight)\n",
        "\n",
        "    # Build comprehensive feature matrix\n",
        "    X = pd.DataFrame({\n",
        "        # Core rating differences\n",
        "        \"elo_diff\": np.where(p1, df.w_e - df.l_e, df.l_e - df.w_e),\n",
        "        \"surf_elo_diff\": np.where(p1, df.w_se - df.l_se, df.l_se - df.w_se),\n",
        "        \"glicko_diff\": np.where(p1, df.w_g - df.l_g, df.l_g - df.w_g),\n",
        "\n",
        "        # Form and momentum\n",
        "        \"form_diff\": np.where(p1, df.w_form - df.l_form, df.l_form - df.w_form),\n",
        "        \"recent_form_diff\": np.where(p1, df.w_recent_form - df.l_recent_form,\n",
        "                                   df.l_recent_form - df.w_recent_form),\n",
        "\n",
        "        # Head-to-head and ranking\n",
        "        \"h2h_adv\": np.where(p1, df.h2h, -df.h2h),\n",
        "        \"rank_diff\": np.where(p1, df.l_rank - df.w_rank, df.w_rank - df.l_rank),\n",
        "        \"rank_pts_diff\": np.where(p1, df.w_pts - df.l_pts, df.l_pts - df.w_pts),\n",
        "\n",
        "        # Physical and style characteristics\n",
        "        \"age_diff\": np.where(p1, df.w_age - df.l_age, df.l_age - df.w_age),\n",
        "        \"height_diff\": np.where(p1, df.w_ht - df.l_ht, df.l_ht - df.w_ht),\n",
        "        \"hand_adv\": np.where(\n",
        "            p1,\n",
        "            ((df.w_hand == 'L') & (df.l_hand == 'R')).astype(int) -\n",
        "            ((df.w_hand == 'R') & (df.l_hand == 'L')).astype(int),\n",
        "            ((df.l_hand == 'L') & (df.w_hand == 'R')).astype(int) -\n",
        "            ((df.l_hand == 'R') & (df.w_hand == 'L')).astype(int)),\n",
        "\n",
        "        # Serving statistics (career averages)\n",
        "        \"career_ace_diff\": np.where(p1, df.w_ace - df.l_ace, df.l_ace - df.w_ace),\n",
        "        \"career_df_diff\": np.where(p1, df.l_df - df.w_df, df.w_df - df.l_df),\n",
        "        \"career_1st_serve_diff\": np.where(p1, df.w_fs - df.l_fs, df.l_fs - df.w_fs),\n",
        "        \"career_1st_win_diff\": np.where(p1, df.w_fw - df.l_fw, df.l_fw - df.w_fw),\n",
        "\n",
        "        # Tournament context\n",
        "        \"is_masters\": (df.tlevel == 'M').astype(int),\n",
        "        \"is_grand_slam\": (df.tlevel == 'G').astype(int),\n",
        "        \"draw_size_log\": np.log2(df.draw),\n",
        "        \"surface_encoded\": surf_enc,\n",
        "\n",
        "        # Advanced rating features\n",
        "        \"elo_momentum\": np.where(p1,\n",
        "                                (df.w_e - 1500) - (df.l_e - 1500),\n",
        "                                (df.l_e - 1500) - (df.w_e - 1500)),\n",
        "        \"rd_diff\": np.where(p1, df.l_rd - df.w_rd, df.w_rd - df.l_rd),\n",
        "        \"min_rd\": np.minimum(df.w_rd, df.l_rd),\n",
        "        \"max_rd\": np.maximum(df.w_rd, df.l_rd),\n",
        "        \"rd_uncertainty_flag\": ((df.w_rd > 100) | (df.l_rd > 100)).astype(int),\n",
        "\n",
        "        # Confidence-weighted features\n",
        "        \"confidence_product\": df.w_confidence * df.l_confidence,\n",
        "        \"confidence_weighted_elo\": np.where(p1,\n",
        "            (df.w_e - df.l_e) * df.w_confidence * df.l_confidence,\n",
        "            (df.l_e - df.w_e) * df.l_confidence * df.w_confidence),\n",
        "        \"glicko_confidence_diff\": np.where(p1,\n",
        "            (df.w_g - df.l_g) * df.w_confidence * df.l_confidence,\n",
        "            (df.l_g - df.w_g) * df.l_confidence * df.w_confidence),\n",
        "\n",
        "        # Activity and freshness features\n",
        "        \"activity_diff\": np.where(p1, df.w_matches_90d - df.l_matches_90d,\n",
        "                                 df.l_matches_90d - df.w_matches_90d),\n",
        "        \"freshness_penalty\": np.where(p1,\n",
        "            np.log1p(df.w_days_since) - np.log1p(df.l_days_since),\n",
        "            np.log1p(df.l_days_since) - np.log1p(df.w_days_since)),\n",
        "        \"rust_factor\": np.maximum(df.w_days_since, df.l_days_since) / 30,\n",
        "        \"surface_experience_diff\": np.where(p1,\n",
        "            df.w_surface_matches - df.l_surface_matches,\n",
        "            df.l_surface_matches - df.w_surface_matches),\n",
        "\n",
        "        # Form confidence features\n",
        "        \"form_confidence\": np.where(p1,\n",
        "            df.w_recent_form * df.w_confidence - df.l_recent_form * df.l_confidence,\n",
        "            df.l_recent_form * df.l_confidence - df.w_recent_form * df.w_confidence),\n",
        "\n",
        "        # Enhanced win probability (Glicko-based)\n",
        "        \"glicko_win_prob\": np.where(p1,\n",
        "            [glicko_win_prob(r1, rd1, r2, rd2) for r1, rd1, r2, rd2 in\n",
        "             zip(df.w_g, df.w_rd, df.l_g, df.l_rd)],\n",
        "            [glicko_win_prob(r2, rd2, r1, rd1) for r1, rd1, r2, rd2 in\n",
        "             zip(df.w_g, df.w_rd, df.l_g, df.l_rd)]),\n",
        "\n",
        "        # Ranking volatility\n",
        "        \"ranking_volatility\": np.where(p1,\n",
        "            np.abs(df.w_rank - 50) - np.abs(df.l_rank - 50),\n",
        "            np.abs(df.l_rank - 50) - np.abs(df.w_rank - 50))\n",
        "    }).fillna(0)\n",
        "\n",
        "    return X, y, df.date, le\n",
        "\n",
        "\n",
        "# ╔══ 5. Train & evaluate XGBoost with GPU support ═══════════════════════════╗\n",
        "def train_evaluate_with_gpu(X, y, dates):\n",
        "    \"\"\"Train XGBoost model with GPU acceleration and proper parameter handling\"\"\"\n",
        "    split = dates.quantile(0.8)\n",
        "    train_mask = dates < split\n",
        "\n",
        "    # Check GPU availability\n",
        "    gpu_available = check_gpu_availability()\n",
        "\n",
        "    # Configure XGBoost parameters based on GPU availability\n",
        "    if gpu_available:\n",
        "        params = {\n",
        "            \"objective\": \"binary:logistic\",\n",
        "            \"eval_metric\": \"logloss\",\n",
        "            \"n_estimators\": 2000,\n",
        "            \"learning_rate\": 0.02,\n",
        "            \"max_depth\": 8,\n",
        "            \"subsample\": 0.8,\n",
        "            \"colsample_bytree\": 0.8,\n",
        "            \"reg_alpha\": 0.1,\n",
        "            \"reg_lambda\": 0.1,\n",
        "            \"random_state\": 42,\n",
        "            \"tree_method\": 'gpu_hist',\n",
        "            \"predictor\": 'gpu_predictor',\n",
        "            \"gpu_id\": 0,\n",
        "            \"early_stopping_rounds\": 100,  # FIXED: Moved to constructor\n",
        "            \"enable_categorical\": False\n",
        "\n",
        "        }\n",
        "        print(\"🚀 Training with GPU acceleration\")\n",
        "    else:\n",
        "        params = {\n",
        "            \"objective\": \"binary:logistic\",\n",
        "            \"eval_metric\": \"logloss\",\n",
        "            \"n_estimators\": 1500,\n",
        "            \"learning_rate\": 0.03,\n",
        "            \"max_depth\": 6,\n",
        "            \"subsample\": 0.8,\n",
        "            \"colsample_bytree\": 0.8,\n",
        "            \"reg_alpha\": 0.1,\n",
        "            \"reg_lambda\": 0.1,\n",
        "            \"random_state\": 42,\n",
        "            \"tree_method\": 'hist',\n",
        "            \"early_stopping_rounds\": 100,  # FIXED: Moved to constructor\n",
        "            \"enable_categorical\": False\n",
        "        }\n",
        "        print(\"🖥️ Training with CPU\")\n",
        "\n",
        "    model = xgb.XGBClassifier(**params)\n",
        "\n",
        "    # FIXED: Removed early_stopping_rounds from fit() method\n",
        "    print(f\"📊 Training on {train_mask.sum():,} samples...\")\n",
        "    model.fit(X[train_mask], y[train_mask],\n",
        "              eval_set=[(X[~train_mask], y[~train_mask])],\n",
        "              verbose=False)\n",
        "\n",
        "    # Evaluate model performance\n",
        "    pred = model.predict(X[~train_mask])\n",
        "    proba = model.predict_proba(X[~train_mask])[:, 1]\n",
        "    acc = accuracy_score(y[~train_mask], pred)\n",
        "    auc = roc_auc_score(y[~train_mask], proba)\n",
        "\n",
        "    device = \"GPU\" if gpu_available else \"CPU\"\n",
        "    print(f\"\\n🎯 {device} TRAINING RESULTS:\")\n",
        "    print(f\"   Accuracy: {acc:.3%}\")\n",
        "    print(f\"   AUC: {auc:.3f}\")\n",
        "    print(f\"   Training samples: {train_mask.sum():,}\")\n",
        "    print(f\"   Validation samples: {(~train_mask).sum():,}\")\n",
        "\n",
        "    # Feature importance analysis\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'feature': X.columns,\n",
        "        'importance': model.feature_importances_\n",
        "    }).sort_values('importance', ascending=False)\n",
        "\n",
        "    print(f\"\\n🏆 TOP 20 MOST IMPORTANT FEATURES:\")\n",
        "    print(feature_importance.head(20).to_string(index=False))\n",
        "\n",
        "    return model, feature_importance\n",
        "\n",
        "# ╔══ 6. Main execution pipeline ═════════════════════════════════════════════╗\n",
        "def main():\n",
        "    \"\"\"Main execution pipeline\"\"\"\n",
        "    print(\"🎾 TENNIS ATP MATCH-WINNER MODEL v6.0 (Complete GPU Version)\")\n",
        "    print(\"🚀 Clean baseline with GPU training support\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Step 1: Download data\n",
        "    csv_files = download_csvs()\n",
        "\n",
        "    # Step 2: Build feature frame\n",
        "    frame = build_feature_frame(csv_files)\n",
        "    print(f\"✅ Created feature frame with {len(frame):,} matches\")\n",
        "\n",
        "    # Add this save step:\n",
        "    print(\"💾 Saving feature frame for backtesting...\")\n",
        "    frame.to_pickle(\"tennis_feature_frame.pkl\")\n",
        "    print(\"✅ Feature frame saved successfully\")\n",
        "\n",
        "    # Step 3: Build feature matrix\n",
        "    print(\"🧮 Building feature matrix...\")\n",
        "    X, y, dates, encoder = build_X_y(frame)\n",
        "    print(f\"✅ Feature matrix: {X.shape[0]:,} samples, {X.shape[1]} features\")\n",
        "\n",
        "    # Step 4: Train model\n",
        "    print(\"🤖 Training model...\")\n",
        "    model, feature_importance = train_evaluate_with_gpu(X, y, dates)\n",
        "\n",
        "    # Step 5: Save model\n",
        "    print(\"💾 Saving model...\")\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "    model_output_path = f\"tennis_model_gpu_complete_{timestamp}.json\"\n",
        "    encoder_output_path = f\"surface_encoder_complete_{timestamp}.pkl\"\n",
        "    importance_output_path = f\"feature_importance_complete_{timestamp}.csv\"\n",
        "\n",
        "    model.save_model(model_output_path)\n",
        "    pickle.dump(encoder, open(encoder_output_path, \"wb\"))\n",
        "    feature_importance.to_csv(importance_output_path, index=False)\n",
        "\n",
        "    print(f\"\\n🎾 COMPLETE GPU MODEL FINISHED!\")\n",
        "    print(f\"📊 Features: {len(X.columns)}\")\n",
        "    print(f\"💾 Model saved: {model_output_path}\")\n",
        "    print(f\"💾 Encoder saved: {encoder_output_path}\")\n",
        "    print(f\"💾 Feature importance saved: {importance_output_path}\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"🏆 Ready for production use!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltwhJPYoD7CJ",
        "outputId": "aa8ed6a3-e1eb-498c-c827-dd6a9901c4f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- MODEL SETUP ---\n",
            "Using manually specified file paths.\n",
            "🔄 Loading model from: tennis_model_gpu_complete_20250707_204740.json\n",
            "✅ Model loaded successfully.\n",
            "🔄 Loading encoder from: surface_encoder_complete_20250707_204740.pkl\n",
            "✅ Encoder loaded successfully.\n",
            "--------------------\n",
            "\n",
            "🎾 TENNIS PREDICTOR IS READY 🎾\n",
            "Instructions:\n",
            "1. Prepare your match data in the JSON format below.\n",
            "2. Paste the entire JSON object into the input box and press Enter.\n",
            "3. To finish, type 'exit' and press Enter.\n",
            "\n",
            "--- JSON TEMPLATE (you can copy this) ---\n",
            "\n",
            "{\n",
            "  \"match_context\": {\n",
            "    \"player_1\": \"Carlos Alcaraz\",\n",
            "    \"player_2\": \"Jannik Sinner\",\n",
            "    \"surface\": \"Grass\",\n",
            "    \"tournament_level\": \"Unknown\",\n",
            "    \"match_id\": \"alcaraz_vs_sinner_grass_simulation\"\n",
            "  },\n",
            "  \"features\": {\n",
            "    \"glicko_confidence_diff\": 0.15, \"glicko_win_prob\": 0.55, \"glicko_diff\": 38,\n",
            "    \"rank_diff\": 1, \"rank_pts_diff\": -1130, \"rd_diff\": 0.08, \"surf_elo_diff\": 173,\n",
            "    \"ranking_volatility\": -0.12, \"form_confidence\": 0.18, \"freshness_penalty\": -0.05,\n",
            "    \"age_diff\": 1, \"is_grand_slam\": 0, \"h2h_adv\": 0.56, \"rd_uncertainty_flag\": 0,\n",
            "    \"min_rd\": 45.2, \"max_rd\": 52.8, \"surface_experience_diff\": 8, \"recent_form_diff\": 0.22,\n",
            "    \"confidence_weighted_elo\": 2267, \"height_diff\": 0, \"draw_size_log\": 4.09,\n",
            "    \"activity_diff\": -0.08, \"confidence_product\": 0.82, \"elo_momentum\": 15.2,\n",
            "    \"elo_diff\": 38, \"rust_factor\": 0.02, \"form_diff\": 0.18, \"is_masters\": 0,\n",
            "    \"surface_encoded\": 2, \"hand_adv\": 0, \"career_1st_win_diff\": 0.024,\n",
            "    \"career_ace_diff\": 0.011, \"career_df_diff\": -0.008, \"career_1st_serve_diff\": 0.003\n",
            "  }\n",
            "}\n",
            "\n",
            "-------------------------------------------\n",
            "\n",
            "\n",
            "👇 Paste your match data JSON here and press Enter (or type 'exit' to quit):\n",
            "{   \"match_context\": {     \"player_1\": \"Taylor Fritz\",     \"player_2\": \"Karen Khachanov\",     \"surface\": \"Grass\",     \"surface_encoded\": 2,     \"tournament_level\": \"Grand Slam\",     \"match_id\": \"fritz_vs_khachanov_grandslam_grass\"   },   \"features\": {     \"glicko_confidence_diff\": 0.25,     \"glicko_win_prob\": 0.66,     \"glicko_diff\": 117,     \"rank_diff\": -15,     \"rank_pts_diff\": 2395,     \"rd_diff\": 0.18,     \"surf_elo_diff\": 135,     \"ranking_volatility\": 0.12,     \"form_confidence\": 0.28,     \"freshness_penalty\": -0.08,     \"age_diff\": 2,     \"is_grand_slam\": 1,     \"h2h_adv\": 0.65,     \"rd_uncertainty_flag\": 0,     \"min_rd\": 35.2,     \"max_rd\": 48.1,     \"surface_experience_diff\": 20,     \"recent_form_diff\": 0.32,     \"confidence_weighted_elo\": 2055,     \"height_diff\": 0,     \"draw_size_log\": 4.16,     \"activity_diff\": 0.15,     \"confidence_product\": 0.88,     \"elo_momentum\": 22.5,     \"elo_diff\": 117,     \"rust_factor\": 0.02,     \"form_diff\": 0.28,     \"is_masters\": 0,     \"surface_encoded\": 2,     \"hand_adv\": 0,     \"career_1st_win_diff\": 0.028,     \"career_ace_diff\": 0.023,     \"career_df_diff\": -0.004,     \"career_1st_serve_diff\": -0.031   },   \"target\": {     \"predicted_win_probability\": 0.735,     \"favorite_player\": \"Taylor Fritz\"   } }\n",
            "\n",
            "==================================================\n",
            "MATCH CONTEXT\n",
            "  Player 1: Taylor Fritz\n",
            "  Player 2: Karen Khachanov\n",
            "  Surface: Grass\n",
            "==================================================\n",
            "\n",
            "🏆 MODEL PREDICTION OUTPUT 🏆\n",
            "{\n",
            "  \"predicted_win_probability\": 0.6102,\n",
            "  \"favorite_player\": \"Taylor Fritz\"\n",
            "}\n",
            "==================================================\n",
            "\n",
            "👇 Paste your match data JSON here and press Enter (or type 'exit' to quit):\n",
            "{   \"match_context\": {     \"player_1\": \"Alexis Galarneau\",     \"player_2\": \"Andres Martin\",     \"surface\": \"Hard\",     \"surface_encoded\": 0,     \"tournament_level\": \"Challenger\",     \"match_id\": \"galarneau_vs_martin_challenger_hard\"   },   \"features\": {     \"glicko_confidence_diff\": 0.18,     \"glicko_win_prob\": 0.52,     \"glicko_diff\": 15,     \"rank_diff\": -146,     \"rank_pts_diff\": 125,     \"rd_diff\": 0.08,     \"surf_elo_diff\": 25,     \"ranking_volatility\": 0.12,     \"form_confidence\": 0.22,     \"freshness_penalty\": -0.08,     \"age_diff\": -2,     \"is_grand_slam\": 0,     \"h2h_adv\": 1.00,     \"rd_uncertainty_flag\": 0,     \"min_rd\": 45.8,     \"max_rd\": 52.1,     \"surface_experience_diff\": 157,     \"recent_form_diff\": 0.20,     \"confidence_weighted_elo\": 1545,     \"height_diff\": 0,     \"draw_size_log\": 3.58,     \"activity_diff\": 0.25,     \"confidence_product\": 0.75,     \"elo_momentum\": 8.5,     \"elo_diff\": 15,     \"rust_factor\": 0.02,     \"form_diff\": 0.18,     \"is_masters\": 0,     \"surface_encoded\": 0,     \"hand_adv\": 0,     \"career_1st_win_diff\": 0.076,     \"career_ace_diff\": 0.003,     \"career_df_diff\": 0.002,     \"career_1st_serve_diff\": -0.031   },   \"target\": {     \"predicted_win_probability\": 0.625,     \"favorite_player\": \"Alexis Galarneau\"   } }\n",
            "\n",
            "==================================================\n",
            "MATCH CONTEXT\n",
            "  Player 1: Alexis Galarneau\n",
            "  Player 2: Andres Martin\n",
            "  Surface: Hard\n",
            "==================================================\n",
            "\n",
            "🏆 MODEL PREDICTION OUTPUT 🏆\n",
            "{\n",
            "  \"predicted_win_probability\": 0.559,\n",
            "  \"favorite_player\": \"Andres Martin\"\n",
            "}\n",
            "==================================================\n",
            "\n",
            "👇 Paste your match data JSON here and press Enter (or type 'exit' to quit):\n",
            "{   \"match_context\": {     \"player_1\": \"Andres Andrade\",     \"player_2\": \"Nicolas Mejia\",     \"surface\": \"Hard\",     \"surface_encoded\": 0,     \"tournament_level\": \"Challenger\",     \"match_id\": \"andrade_vs_mejia_challenger_hard\"   },   \"features\": {     \"glicko_confidence_diff\": 0.35,     \"glicko_win_prob\": 0.51,     \"glicko_diff\": 10,     \"rank_diff\": 19,     \"rank_pts_diff\": -21,     \"rd_diff\": 0.25,     \"surf_elo_diff\": 125,     \"ranking_volatility\": 0.08,     \"form_confidence\": 0.42,     \"freshness_penalty\": -0.02,     \"age_diff\": -1,     \"is_grand_slam\": 0,     \"h2h_adv\": 1.00,     \"rd_uncertainty_flag\": 0,     \"min_rd\": 45.2,     \"max_rd\": 48.8,     \"surface_experience_diff\": 16,     \"recent_form_diff\": 0.38,     \"confidence_weighted_elo\": 1520,     \"height_diff\": 0,     \"draw_size_log\": 3.58,     \"activity_diff\": -0.18,     \"confidence_product\": 0.72,     \"elo_momentum\": 5.8,     \"elo_diff\": 10,     \"rust_factor\": 0.02,     \"form_diff\": 0.35,     \"is_masters\": 0,     \"surface_encoded\": 0,     \"hand_adv\": 0,     \"career_1st_win_diff\": 0.010,     \"career_ace_diff\": 0.009,     \"career_df_diff\": 0.001,     \"career_1st_serve_diff\": -0.087   },   \"target\": {     \"predicted_win_probability\": 0.785,     \"favorite_player\": \"Andres Andrade\"   } }\n",
            "\n",
            "==================================================\n",
            "MATCH CONTEXT\n",
            "  Player 1: Andres Andrade\n",
            "  Player 2: Nicolas Mejia\n",
            "  Surface: Hard\n",
            "==================================================\n",
            "\n",
            "🏆 MODEL PREDICTION OUTPUT 🏆\n",
            "{\n",
            "  \"predicted_win_probability\": 0.5381,\n",
            "  \"favorite_player\": \"Andres Andrade\"\n",
            "}\n",
            "==================================================\n",
            "\n",
            "👇 Paste your match data JSON here and press Enter (or type 'exit' to quit):\n"
          ]
        }
      ],
      "source": [
        "### ======================================================= ###\n",
        "###   INTERACTIVE TENNIS MATCH PREDICTION CELL FOR COLAB    ###\n",
        "###        (FIXED JSON Serialization Error)               ###\n",
        "### ======================================================= ###\n",
        "\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "import pickle\n",
        "import json\n",
        "import os\n",
        "\n",
        "# --- 1. Configuration: Updated with the filenames from your image ---\n",
        "MANUAL_MODEL_PATH = \"tennis_model_gpu_complete_20250707_204740.json\"\n",
        "MANUAL_ENCODER_PATH = \"surface_encoder_complete_20250707_204740.pkl\"\n",
        "\n",
        "\n",
        "# --- 2. Helper Functions (with the fix) ---\n",
        "\n",
        "def find_latest_files():\n",
        "    \"\"\"Finds the most recently created model and encoder files in the current directory.\"\"\"\n",
        "    models = sorted([f for f in os.listdir() if f.startswith('tennis_model_gpu_complete') and f.endswith('.json')])\n",
        "    encoders = sorted([f for f in os.listdir() if f.startswith('surface_encoder_complete') and f.endswith('.pkl')])\n",
        "\n",
        "    if not models or not encoders:\n",
        "        return None, None\n",
        "\n",
        "    return models[-1], encoders[-1]\n",
        "\n",
        "def load_model_and_encoder(model_path, encoder_path):\n",
        "    \"\"\"Loads the trained XGBoost model and the surface encoder from disk.\"\"\"\n",
        "    print(f\"🔄 Loading model from: {model_path}\")\n",
        "    model = xgb.XGBClassifier()\n",
        "    model.load_model(model_path)\n",
        "    print(\"✅ Model loaded successfully.\")\n",
        "\n",
        "    print(f\"🔄 Loading encoder from: {encoder_path}\")\n",
        "    with open(encoder_path, 'rb') as f:\n",
        "        encoder = pickle.load(f)\n",
        "    print(\"✅ Encoder loaded successfully.\")\n",
        "\n",
        "    return model, encoder\n",
        "\n",
        "def predict_match(model, input_data: dict):\n",
        "    \"\"\"Predicts the outcome of a tennis match from the structured JSON input.\"\"\"\n",
        "    features = input_data[\"features\"]\n",
        "    context = input_data[\"match_context\"]\n",
        "    p1_name = context[\"player_1\"]\n",
        "\n",
        "    input_df = pd.DataFrame([features])\n",
        "    model_feature_names = model.get_booster().feature_names\n",
        "    input_df = input_df[model_feature_names]\n",
        "\n",
        "    win_prob_p1 = model.predict_proba(input_df)[0][1]\n",
        "\n",
        "    if win_prob_p1 >= 0.5:\n",
        "        favorite_player = context[\"player_1\"]\n",
        "        predicted_probability = win_prob_p1\n",
        "    else:\n",
        "        favorite_player = context[\"player_2\"]\n",
        "        predicted_probability = 1 - win_prob_p1\n",
        "\n",
        "    # ================================================================= #\n",
        "    # ▼▼▼ THE FIX IS HERE ▼▼▼\n",
        "    # We explicitly convert the numpy.float32 to a standard Python float\n",
        "    # before rounding and adding it to the dictionary.\n",
        "    # ================================================================= #\n",
        "    result = {\n",
        "        \"predicted_win_probability\": round(float(predicted_probability), 4),\n",
        "        \"favorite_player\": favorite_player\n",
        "    }\n",
        "    return result\n",
        "\n",
        "# --- 3. Main Interactive Execution ---\n",
        "\n",
        "# This is the example data structure. You can copy this.\n",
        "EXAMPLE_JSON_STRING = \"\"\"\n",
        "{\n",
        "  \"match_context\": {\n",
        "    \"player_1\": \"Carlos Alcaraz\",\n",
        "    \"player_2\": \"Jannik Sinner\",\n",
        "    \"surface\": \"Grass\",\n",
        "    \"tournament_level\": \"Unknown\",\n",
        "    \"match_id\": \"alcaraz_vs_sinner_grass_simulation\"\n",
        "  },\n",
        "  \"features\": {\n",
        "    \"glicko_confidence_diff\": 0.15, \"glicko_win_prob\": 0.55, \"glicko_diff\": 38,\n",
        "    \"rank_diff\": 1, \"rank_pts_diff\": -1130, \"rd_diff\": 0.08, \"surf_elo_diff\": 173,\n",
        "    \"ranking_volatility\": -0.12, \"form_confidence\": 0.18, \"freshness_penalty\": -0.05,\n",
        "    \"age_diff\": 1, \"is_grand_slam\": 0, \"h2h_adv\": 0.56, \"rd_uncertainty_flag\": 0,\n",
        "    \"min_rd\": 45.2, \"max_rd\": 52.8, \"surface_experience_diff\": 8, \"recent_form_diff\": 0.22,\n",
        "    \"confidence_weighted_elo\": 2267, \"height_diff\": 0, \"draw_size_log\": 4.09,\n",
        "    \"activity_diff\": -0.08, \"confidence_product\": 0.82, \"elo_momentum\": 15.2,\n",
        "    \"elo_diff\": 38, \"rust_factor\": 0.02, \"form_diff\": 0.18, \"is_masters\": 0,\n",
        "    \"surface_encoded\": 2, \"hand_adv\": 0, \"career_1st_win_diff\": 0.024,\n",
        "    \"career_ace_diff\": 0.011, \"career_df_diff\": -0.008, \"career_1st_serve_diff\": 0.003\n",
        "  }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    # --- SETUP: Load the model and encoder ---\n",
        "    print(\"--- MODEL SETUP ---\")\n",
        "    if MANUAL_MODEL_PATH and MANUAL_ENCODER_PATH:\n",
        "        print(\"Using manually specified file paths.\")\n",
        "        model_path, encoder_path = MANUAL_MODEL_PATH, MANUAL_ENCODER_PATH\n",
        "    else:\n",
        "        print(\"Attempting to find latest files automatically...\")\n",
        "        model_path, encoder_path = find_latest_files()\n",
        "\n",
        "    if not model_path or not encoder_path:\n",
        "        raise FileNotFoundError(\"Could not find model/encoder files.\")\n",
        "\n",
        "    tennis_model, surface_encoder = load_model_and_encoder(model_path, encoder_path)\n",
        "    print(\"-\" * 20)\n",
        "\n",
        "    # --- INTERACTIVE PREDICTION LOOP ---\n",
        "    print(\"\\n🎾 TENNIS PREDICTOR IS READY 🎾\")\n",
        "    print(\"Instructions:\")\n",
        "    print(\"1. Prepare your match data in the JSON format below.\")\n",
        "    print(\"2. Paste the entire JSON object into the input box and press Enter.\")\n",
        "    print(\"3. To finish, type 'exit' and press Enter.\")\n",
        "    print(\"\\n--- JSON TEMPLATE (you can copy this) ---\")\n",
        "    print(EXAMPLE_JSON_STRING)\n",
        "    print(\"-------------------------------------------\\n\")\n",
        "\n",
        "    while True:\n",
        "        # Prompt user for multi-line input\n",
        "        print(\"\\n👇 Paste your match data JSON here and press Enter (or type 'exit' to quit):\")\n",
        "        user_input_str = input()\n",
        "\n",
        "        if user_input_str.strip().lower() == 'exit':\n",
        "            print(\"👋 Exiting predictor. Goodbye!\")\n",
        "            break\n",
        "\n",
        "        if not user_input_str.strip():\n",
        "            print(\"⚠️ Input is empty. Please paste the JSON data or type 'exit'.\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # Parse the user's string input into a Python dictionary\n",
        "            input_data = json.loads(user_input_str)\n",
        "\n",
        "            # Get the prediction\n",
        "            prediction_result = predict_match(tennis_model, input_data)\n",
        "\n",
        "            # Display the result\n",
        "            print(\"\\n\" + \"=\"*50)\n",
        "            print(\"MATCH CONTEXT\")\n",
        "            print(f\"  Player 1: {input_data['match_context']['player_1']}\")\n",
        "            print(f\"  Player 2: {input_data['match_context']['player_2']}\")\n",
        "            print(f\"  Surface: {input_data['match_context']['surface']}\")\n",
        "            print(\"=\"*50)\n",
        "            print(\"\\n🏆 MODEL PREDICTION OUTPUT 🏆\")\n",
        "            print(json.dumps(prediction_result, indent=2))\n",
        "            print(\"=\"*50)\n",
        "\n",
        "        except json.JSONDecodeError:\n",
        "            print(\"\\n❌ ERROR: Invalid JSON format. Please check your pasted text.\")\n",
        "            print(\"Common mistakes include missing commas, brackets {}, or quotes \\\"\\\".\")\n",
        "        except KeyError as e:\n",
        "            print(f\"\\n❌ ERROR: The provided JSON is missing a required key: {e}\")\n",
        "            print(\"Please ensure 'match_context' and 'features' keys are present.\")\n",
        "        except Exception as e:\n",
        "            print(f\"\\n❌ An unexpected error occurred: {e}\")\n",
        "\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"\\n\" + \"!\"*50)\n",
        "    print(\"🔥 ERROR: MODEL OR ENCODER FILE NOT FOUND! 🔥\")\n",
        "    print(f\"The script was looking for '{MANUAL_MODEL_PATH}' and '{MANUAL_ENCODER_PATH}'.\")\n",
        "    print(\"Please make sure these files exist in your Colab session directory.\")\n",
        "    print(\"You may need to run the training cell again.\")\n",
        "    print(\"!\"*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwoY47KNLPMF"
      },
      "outputs": [],
      "source": [
        "import asyncio\n",
        "import datetime\n",
        "import csv\n",
        "from playwright.async_api import async_playwright\n",
        "\n",
        "# List of words to filter out from tournament names/categories.\n",
        "# Added \"wta\" to the list. Case-insensitive.\n",
        "FILTER_KEYWORDS = [\"itf\", \"utr\", \"wta\", \"wheelchairs\", \"girls\", \"junior\", \"challenger\"]\n",
        "\n",
        "async def get_and_write_matches(date_str: str, csv_writer):\n",
        "    \"\"\"\n",
        "    Uses Playwright to fetch match data, filters for non-ITF/UTR/WTA singles matches,\n",
        "    and writes the results to a CSV file.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Scraping Matches for {date_str} ---\")\n",
        "\n",
        "    matches_url = f\"https://api.sofascore.com/api/v1/sport/tennis/scheduled-events/{date_str}\"\n",
        "\n",
        "    # JavaScript to execute in the browser to fetch API data\n",
        "    js_to_fetch_data = f\"\"\"\n",
        "        async () => {{\n",
        "            try {{\n",
        "                const response = await fetch('{matches_url}');\n",
        "                if (!response.ok) {{\n",
        "                    return {{'error': `API responded with status: ${{response.status}}`}};\n",
        "                }}\n",
        "                return await response.json();\n",
        "            }} catch (e) {{\n",
        "                return {{'error': e.toString()}};\n",
        "            }}\n",
        "        }}\n",
        "    \"\"\"\n",
        "\n",
        "    match_data = None\n",
        "    try:\n",
        "        async with async_playwright() as p:\n",
        "            browser = await p.chromium.launch(headless=True)\n",
        "            page = await browser.new_page()\n",
        "\n",
        "            print(\"Initializing browser session...\")\n",
        "            await page.goto(\"https://www.sofascore.com/tennis\", wait_until=\"domcontentloaded\")\n",
        "            print(\"Session established. Fetching data...\")\n",
        "\n",
        "            match_data = await page.evaluate(js_to_fetch_data)\n",
        "\n",
        "            await browser.close()\n",
        "            print(\"Browser closed.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[!!] An error occurred during Playwright execution: {e}\")\n",
        "        return\n",
        "\n",
        "    if not match_data or match_data.get('error'):\n",
        "        print(f\"[!!] FAILED to fetch matches for {date_str}.\")\n",
        "        if match_data:\n",
        "            print(f\"    Error from browser fetch: {match_data.get('error')}\")\n",
        "        return\n",
        "\n",
        "    events = match_data.get('events', [])\n",
        "    if not events:\n",
        "        print(\"No matches found for this date.\")\n",
        "        return\n",
        "\n",
        "    print(f\"Found {len(events)} total events. Filtering and writing to CSV...\")\n",
        "\n",
        "    count_written = 0\n",
        "    for event in events:\n",
        "        category = event.get('tournament', {}).get('category', {}).get('name', 'N/A')\n",
        "        tournament_name = event.get('tournament', {}).get('name', 'N/A')\n",
        "        home_team = event.get('homeTeam', {}).get('name', 'N/A')\n",
        "        away_team = event.get('awayTeam', {}).get('name', 'N/A')\n",
        "\n",
        "        # Combine category and tournament name for easier filtering\n",
        "        full_tournament_info = f\"{category} {tournament_name}\".lower()\n",
        "\n",
        "        # --- NEW & IMPROVED FILTERING LOGIC ---\n",
        "        # 1. Skip if the combined info contains any filter keyword (ITF, UTR, WTA)\n",
        "        if any(keyword in full_tournament_info for keyword in FILTER_KEYWORDS):\n",
        "            continue\n",
        "\n",
        "        # 2. Skip if it's a doubles match\n",
        "        if \"doubles\" in full_tournament_info or \"/\" in home_team or \"/\" in away_team:\n",
        "            continue\n",
        "\n",
        "        # If the event passed all filters, extract its data\n",
        "        start_timestamp = event.get('startTimestamp')\n",
        "        match_time = datetime.datetime.fromtimestamp(start_timestamp).strftime('%H:%M')\n",
        "\n",
        "        # Write the filtered row to the CSV\n",
        "        csv_writer.writerow([\n",
        "            date_str,\n",
        "            match_time,\n",
        "            category,\n",
        "            tournament_name,\n",
        "            home_team,\n",
        "            away_team\n",
        "        ])\n",
        "        count_written += 1\n",
        "\n",
        "    print(f\"Wrote {count_written} filtered matches to the CSV file.\")\n",
        "\n",
        "async def main():\n",
        "    \"\"\"Main function to orchestrate the scraping and CSV writing.\"\"\"\n",
        "    today = datetime.date.today()\n",
        "    tomorrow = today + datetime.timedelta(days=1)\n",
        "\n",
        "    today_str = today.strftime('%Y-%m-%d')\n",
        "    tomorrow_str = tomorrow.strftime('%Y-%m-%d')\n",
        "\n",
        "    output_filename = \"sofascore_filtered_matches.csv\"\n",
        "\n",
        "    with open(output_filename, 'w', newline='', encoding='utf-8') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow(['Date', 'Time', 'Category', 'Tournament', 'Player 1', 'Player 2'])\n",
        "\n",
        "        await get_and_write_matches(today_str, writer)\n",
        "        await get_and_write_matches(tomorrow_str, writer)\n",
        "\n",
        "    print(f\"\\n✅ All done! Data saved to '{output_filename}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBHK4le9NQaT",
        "outputId": "b1b3d229-1657-4968-a9f7-7bb33b640dbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Scraping Matches for 2025-07-10 ---\n",
            "Initializing browser session...\n",
            "Session established. Fetching data...\n",
            "Browser closed.\n",
            "Found 946 total events. Filtering and writing to CSV...\n",
            "Wrote 4 filtered matches to the CSV file.\n",
            "\n",
            "--- Scraping Matches for 2025-07-11 ---\n",
            "Initializing browser session...\n",
            "Session established. Fetching data...\n",
            "Browser closed.\n",
            "Found 329 total events. Filtering and writing to CSV...\n",
            "Wrote 4 filtered matches to the CSV file.\n",
            "\n",
            "✅ All done! Data saved to 'sofascore_filtered_matches.csv'\n"
          ]
        }
      ],
      "source": [
        "await main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNELiL9nUU_u",
        "outputId": "72f333dc-3122-492a-8d33-231936db12df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved 487 players to atp_elo_directory.csv\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "extract_main_table.py\n",
        "Fetch the main Elo table and save as CSV, without pd.read_html warnings.\n",
        "\"\"\"\n",
        "\n",
        "import requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from io import StringIO\n",
        "\n",
        "INDEX_URL = \"https://tennisabstract.com/reports/atp_elo_ratings.html\"\n",
        "OUTPUT_CSV = \"atp_elo_directory.csv\"\n",
        "\n",
        "def fetch_and_save_directory():\n",
        "    # 1. Download page\n",
        "    resp = requests.get(INDEX_URL, timeout=30)\n",
        "    resp.raise_for_status()\n",
        "\n",
        "    # 2. Parse the Elo table\n",
        "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
        "    table = soup.find(\"table\", id=\"reportable\")\n",
        "    if not table:\n",
        "        raise RuntimeError(\"Could not find table#reportable\")\n",
        "\n",
        "    # 3. Read into DataFrame via StringIO\n",
        "    html = StringIO(str(table))\n",
        "    df = pd.read_html(html, header=0)[0]\n",
        "\n",
        "    # 4. Extract profile URLs\n",
        "    hrefs = []\n",
        "    for row in table.tbody.find_all(\"tr\"):\n",
        "        a = row.find(\"a\", href=True)\n",
        "        hrefs.append(a[\"href\"] if a else \"\")\n",
        "\n",
        "    df[\"ProfileURL\"] = [\"https://tennisabstract.com\" + h for h in hrefs]\n",
        "\n",
        "    # 5. Save to CSV\n",
        "    df.to_csv(OUTPUT_CSV, index=False)\n",
        "    print(f\"Saved {len(df)} players to {OUTPUT_CSV}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    fetch_and_save_directory()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOA0j9ESfBxwkG2gVeYpfCe",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}